{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch, pickle, math, os\n",
    "import numpy as np\n",
    "from os.path import join, dirname, expanduser, exists\n",
    "from torch.nn.functional import softmax\n",
    "from collections import defaultdict\n",
    "lab_dnn = torch.load(\"lab_dnn.pt\")\n",
    "out = torch.load(\"out.pt\")\n",
    "lab_conc = np.load(\"lab_conc.npy\", allow_pickle=True)\n",
    "mapping = np.load(\"mapping.npy\")\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "conf_dir = join(expanduser(\"~\"), \"UPM\", \"conf\")\n",
    "phones_filepath = join(conf_dir, \"articulatory_features\", \"phone_attributes_filtered.txt\")\n",
    "feats_filepath = join(conf_dir, \"articulatory_features\", \"feature_vectors.txt\")\n",
    "extensions_filepath = join(conf_dir, \"articulatory_features\", \"extensions_filtered.txt\")\n",
    "curr_dir = os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr = np.arange(0,1,0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_phones(filename, confdir):\n",
    "    filepath = join(confdir, filename)\n",
    "    \n",
    "    with open(filepath, \"r\", encoding=\"utf-8\") as f:\n",
    "        out = [line.split()[2] for line in f]\n",
    "        \n",
    "    out = [x for x in out if x.lower() not in [\"sil\", \"unk\"]]\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_all_phones(langs, confdir):\n",
    "    all_phones = []\n",
    "    conf_maps = join(confdir, \"phone_maps\")\n",
    "    for lang in langs:\n",
    "        filename = \"{}_phone_map.txt\".format(lang)\n",
    "        lang_phones = get_phones(filename, conf_maps)\n",
    "        all_phones += lang_phones\n",
    "    all_phones = list(set(all_phones))\n",
    "    return all_phones\n",
    "\n",
    "langs = [\"BG\", \"CR\", \"HA\", \"PL\", \"TU\", \"UA\", \"SA\", \"SW\"]\n",
    "all_phones = combine_all_phones(langs, conf_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_diphthongs(all_phones):\n",
    "    vowels = [\"a\", \"e\", \"i\", \"o\", \"u\", \"y\"]\n",
    "    diphthongs = []\n",
    "    for phone in all_phones:\n",
    "        if len(phone) > 1:\n",
    "            if phone[0] in vowels and phone[1] in vowels:\n",
    "                diphthongs.append(phone)\n",
    "    return diphthongs\n",
    "\n",
    "dips = get_diphthongs(all_phones)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(list,\n",
       "            {'ai': ['close', 'front', 'open', 'unrounded', 'vowel'],\n",
       "             'au': ['back',\n",
       "              'close',\n",
       "              'front',\n",
       "              'open',\n",
       "              'rounded',\n",
       "              'unrounded',\n",
       "              'vowel'],\n",
       "             'ya': ['close', 'front', 'open', 'rounded', 'unrounded', 'vowel'],\n",
       "             'yu': ['back', 'close', 'front', 'rounded', 'vowel']})"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_diphthong_atts(dips, conf_dir):\n",
    "    feat_file = join(conf_dir, \"articulatory_features\", \"feature_vectors.txt\")\n",
    "    with open(feat_file, \"r\") as f:\n",
    "        feat_lines = f.read().splitlines()\n",
    "    header = feat_lines[0].split()\n",
    "    \n",
    "    dips_dict = defaultdict(list)\n",
    "    for line in feat_lines:\n",
    "        entry = line.split()\n",
    "        phone = entry[0]\n",
    "        if phone in dips:\n",
    "            dip = entry[0]\n",
    "            for idx, att in enumerate(entry):\n",
    "                if att == \"1\":\n",
    "                    dips_dict[dip].append(header[idx])\n",
    "    return dips_dict\n",
    "get_diphthong_atts(dips, conf_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['yu', 'ai', 'ya', 'au']"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dips"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "lab_chunks = np.load(\"lab_chunks.npy\", allow_pickle=True)\n",
    "fea_chunks = np.load(\"fea_chunks.npy\", allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO convert phone to phones.txt when reading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(265, dtype=int64)"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(lab_single == pred).sum().detach().cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def filter_valid_extensions(extensions_filepath, phones_idx_dict, feat_idx_dict):\n",
    "    vowel_extensions = []\n",
    "    consonant_extensions = []\n",
    "    with open(extensions_filepath, \"r\") as f:\n",
    "        lines = f.read().splitlines()\n",
    "        \n",
    "    for line in lines:\n",
    "        is_valid = False\n",
    "        entry = line.split()\n",
    "        extension = entry[0]\n",
    "        # Check if extension occurs in any of the phones\n",
    "        for phone in phones_idx_dict:\n",
    "            if extension in phone:\n",
    "                is_valid = True\n",
    "        \n",
    "        if is_valid:\n",
    "            extension_atts = [feat_idx_dict[x] for x in entry[1:]]\n",
    "            if extension in [\":\"]: # This extension seems to only apply to vowels\n",
    "                vowel_extensions.append([extension] + extension_atts)\n",
    "            else:\n",
    "                consonant_extensions.append([extension] + extension_atts)\n",
    "    return vowel_extensions, consonant_extensions\n",
    "\n",
    "def get_phone_idx_dict(phones_txt_filepath):\n",
    "    with open(phones_txt_filepath, \"r\") as f:\n",
    "        phone_to_idx_dict = {}\n",
    "        for line in f:\n",
    "            entry = line.split()\n",
    "            phone = entry[0]\n",
    "            idx = int(entry[1])\n",
    "            phone_to_idx_dict[phone] = idx\n",
    "    return phone_to_idx_dict\n",
    "\n",
    "def mapping_to_labels(mapping, lab_dnn):\n",
    "    lab_detached = lab_dnn.detach().cpu().numpy()\n",
    "    outputs = np.zeros(lab_detached.shape[0])\n",
    "    for lab_idx, lab in enumerate(lab_detached):\n",
    "        if sum(lab) == 0:\n",
    "            outputs[lab_idx] = 1\n",
    "        else:\n",
    "            for mapping_idx, map_val in enumerate(mapping):\n",
    "                if np.array_equal(map_val, lab):\n",
    "                    outputs[lab_idx] = mapping_idx\n",
    "    return outputs\n",
    "\n",
    "def get_feat_idx(feats_filepath):\n",
    "    with open(feats_filepath, \"r\") as f:\n",
    "        header = f.readline()\n",
    "    features = header.split()[1:]\n",
    "    feat_idx_dict = {}\n",
    "    for idx, feat in enumerate(features):\n",
    "        feat_idx_dict[feat] = idx\n",
    "    return feat_idx_dict\n",
    "        \n",
    "def add_extensions(extensions, phones, curr_phone, phone_to_idx_dict, remove_val, delete_vowel_consonant_idx):\n",
    "    # Each extension is of the format [\":\", 3, 2]\n",
    "    \n",
    "    if curr_phone[0] not in ['yu', 'ai', 'ya', 'au']:\n",
    "        for extension in extensions:\n",
    "            # Only add new attributes\n",
    "            atts_to_add = [x for x in extension[1:] if x not in curr_phone[1:]]\n",
    "            if len(atts_to_add) > 0:\n",
    "                ext_phone = curr_phone[0] + extension[0]\n",
    "                if ext_phone in phone_to_idx_dict:\n",
    "                    ext_phone_idx = phone_to_idx_dict[ext_phone]\n",
    "                else:\n",
    "                    ext_phone_idx = 0\n",
    "                ext_feat = [ext_phone_idx] + curr_phone[1:] + atts_to_add\n",
    "                if delete_vowel_consonant_idx:\n",
    "                    ext_feat.remove(remove_val)\n",
    "                phones.append(ext_feat)\n",
    "    return phones\n",
    "    \n",
    "def get_phones(phones_filepath, feat_idx_dict, phone_to_idx_dict, ve, ce, include_extensions=True, delete_vowel_consonant_idx=True):\n",
    "    # ve, ce are vowel and consonant extensions to add\n",
    "    with open(phones_filepath, \"r\") as f:\n",
    "        lines = f.read().splitlines()\n",
    "    vowel_phones = []\n",
    "    consonant_phones = []\n",
    "    vowel_idx = feat_idx_dict[\"vowel\"]\n",
    "    consonant_idx = feat_idx_dict[\"consonant\"]  \n",
    "    \n",
    "    for line in lines:\n",
    "        # Entry = [\"a\", \"front\", \"close\", etc.]\n",
    "        entry = line.split()\n",
    "        is_vowel = False\n",
    "        # Convert to indices for speed\n",
    "        for idx, att in enumerate(entry):\n",
    "            if att == \"vowel\":\n",
    "                remove_idx = idx\n",
    "                is_vowel = True\n",
    "            elif att == \"consonant\":\n",
    "                remove_idx = idx\n",
    "                \n",
    "            if att in feat_idx_dict:\n",
    "                entry[idx] = feat_idx_dict[att]\n",
    "                \n",
    "        if is_vowel and include_extensions:\n",
    "            vowel_phones = add_extensions(ve, vowel_phones, entry, phone_to_idx_dict, vowel_idx, delete_vowel_consonant_idx)\n",
    "        elif include_extensions:\n",
    "            consonant_phones = add_extensions(ce, consonant_phones, entry, phone_to_idx_dict, consonant_idx, delete_vowel_consonant_idx)\n",
    " \n",
    "        # Entry[0] is the phone e.g. \"a\"\n",
    "        phone = entry[0]\n",
    "        # Special case for J\\: (rare incidence of consonant + long in Turkish)\n",
    "        if phone == \"J\\\\\" and \"J\\\\:\" in phone_to_idx_dict:\n",
    "            long_idx = feat_idx_dict[\"long\"]\n",
    "            extra_phone_idx = phone_to_idx_dict[\"J\\\\:\"]\n",
    "            extra_feat = [extra_phone_idx] + entry[1:] + [long_idx]\n",
    "            extra_feat.remove(consonant_idx)\n",
    "            consonant_phones.append(extra_feat)\n",
    "            \n",
    "        if phone in phone_to_idx_dict:\n",
    "            entry[0] = phone_to_idx_dict[phone]\n",
    "        else:\n",
    "            # Set unknown phones to <eps> ?\n",
    "            entry[0] = 0\n",
    "        if delete_vowel_consonant_idx:\n",
    "            del entry[remove_idx]\n",
    "        if is_vowel:\n",
    "            vowel_phones.append(entry)\n",
    "        else:\n",
    "            consonant_phones.append(entry)\n",
    "\n",
    "    return vowel_phones, consonant_phones\n",
    "\n",
    "# Need to initially split between vowels and consonants before further on features\n",
    "def initial_split(phones, feat_idx_dict):\n",
    "    vowel_phones = []\n",
    "    consonant_phones = []\n",
    "    vowel_idx = feat_idx_dict[\"vowel\"]\n",
    "    consonant_idx = feat_idx_dict[\"consonant\"]\n",
    "    for phone in phones:\n",
    "        if vowel_idx in phone:\n",
    "            phone.remove(vowel_idx)\n",
    "            vowel_phones.append(np.asarray(phone))\n",
    "\n",
    "        elif consonant_idx in phone:\n",
    "            phone.remove(consonant_idx)\n",
    "            consonant_phones.append(np.asarray(phone))\n",
    "                    \n",
    "    vowel_phones = np.asarray(vowel_phones)\n",
    "    consonant_phones = np.asarray(consonant_phones)\n",
    "    return vowel_phones, consonant_phones\n",
    "\n",
    "def save_variables(feat_idx_dict, vp, cp, vp_idx, cp_idx, filename=None, save_dir=None):\n",
    "    if save_dir is None:\n",
    "        save_dir = os.getcwd()\n",
    "    if filename is None:\n",
    "        save_path = join(save_dir, \"feat_vars.pkl\")\n",
    "    else:\n",
    "        save_path = join(save_dir, filename + \".pkl\")\n",
    "    with open(save_path, 'wb') as f:\n",
    "        pickle.dump([feat_idx_dict, vp, cp, vp_idx, cp_idx], f)\n",
    "\n",
    "feats_filepath = join(conf_dir, \"articulatory_features\", \"feature_vectors.txt\")\n",
    "phones_filepath = join(conf_dir, \"articulatory_features\", \"phone_attributes_filtered.txt\")\n",
    "phones_list_filepath = join(dirname(os.getcwd()), \"notes\", \"phones.txt\")\n",
    "phone_idx_dict = get_phone_idx_dict(phones_list_filepath)\n",
    "feat_idx_dict = get_feat_idx(feats_filepath)\n",
    "ve, ce = filter_valid_extensions(extensions_filepath, phone_idx_dict, feat_idx_dict)\n",
    "\n",
    "\n",
    "vp, cp = get_phones(phones_filepath, feat_idx_dict, phone_idx_dict, ve, ce)\n",
    "\n",
    "# Get tensor of consonants e.g [0 3 4 5 112 1] - avoids excessive converting to and from tensors\n",
    "cp_idx = [x[0] for x in cp]\n",
    "cp_idx = torch.from_numpy(np.asarray(cp_idx))\n",
    "\n",
    "# Get tensor of consonants e.g [0 3 4 5 112 1] - avoids excessive converting to and from tensors\n",
    "vp_idx = [x[0] for x in vp]\n",
    "vp_idx = torch.from_numpy(np.asarray(vp_idx))\n",
    "\n",
    "save_variables(feat_idx_dict, vp, cp, vp_idx, cp_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[35, 34, 21, 45, 29],\n",
       " [34, 34, 21, 45],\n",
       " [53, 12, 21, 45, 29],\n",
       " [52, 12, 21, 45],\n",
       " [64, 11, 21, 45, 29],\n",
       " [63, 11, 21, 45],\n",
       " [81, 12, 6, 42, 29],\n",
       " [80, 12, 6, 42],\n",
       " [101, 11, 6, 42, 29],\n",
       " [100, 11, 6, 42],\n",
       " [111, 11, 21, 42, 29],\n",
       " [110, 11, 21, 42],\n",
       " [12, 34, 6, 45, 29],\n",
       " [11, 34, 6, 45],\n",
       " [16, 35, 21, 45, 29],\n",
       " [15, 35, 21, 45],\n",
       " [0, 31, 21, 45, 29],\n",
       " [19, 31, 21, 45],\n",
       " [0, 31, 9, 45, 29],\n",
       " [0, 31, 9, 45],\n",
       " [0, 11, 6, 45, 29],\n",
       " [24, 11, 6, 45],\n",
       " [0, 35, 6, 42, 29],\n",
       " [26, 35, 6, 42],\n",
       " [0, 34, 6, 42, 29],\n",
       " [0, 34, 6, 42],\n",
       " [0, 31, 6, 42, 29],\n",
       " [31, 31, 6, 42],\n",
       " [0, 31, 9, 42, 29],\n",
       " [0, 31, 9, 42],\n",
       " [0, 35, 6, 45, 29],\n",
       " [0, 35, 6, 45],\n",
       " [0, 31, 21, 42, 29],\n",
       " [0, 31, 21, 42],\n",
       " [0, 12, 35, 9, 42, 45, 29],\n",
       " [10, 12, 35, 9, 42, 45],\n",
       " [118, 32, 21, 45, 29],\n",
       " [117, 32, 21, 45],\n",
       " [119, 11, 9, 42, 29],\n",
       " [0, 11, 9, 42],\n",
       " [0, 11, 9, 45, 29],\n",
       " [3, 11, 9, 45],\n",
       " [0, 12, 21, 42, 29],\n",
       " [4, 12, 21, 42],\n",
       " [0, 35, 9, 45, 29],\n",
       " [0, 35, 9, 45],\n",
       " [0, 35, 9, 42, 29],\n",
       " [0, 35, 9, 42],\n",
       " [0, 32, 9, 29],\n",
       " [0, 32, 9],\n",
       " [0, 12, 6, 45, 29],\n",
       " [6, 12, 6, 45],\n",
       " [0, 12, 9, 42, 29],\n",
       " [0, 12, 9, 42],\n",
       " [8, 35, 21, 42, 29],\n",
       " [7, 35, 21, 42],\n",
       " [0, 34, 21, 42, 29],\n",
       " [0, 34, 21, 42],\n",
       " [36, 11, 21, 45, 34],\n",
       " [37, 6, 11, 21, 34, 42, 45],\n",
       " [112, 21, 34, 42, 45, 11],\n",
       " [113, 6, 11, 21, 42]]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing to C:\\Users\\Paul\\UPM\\pytorch-kaldi\\universal_phones.txt\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\Paul\\\\UPM\\\\pytorch-kaldi\\\\universal_phones.txt'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def build_universal_phonemap(phones_filepath, ve, ce, write_filepath=None):\n",
    "    with open(phones_filepath, \"r\") as f:\n",
    "        lines = f.read().splitlines()\n",
    "    \n",
    "    write_lines = [\"<eps> 0\", \"sil 1\"]\n",
    "    next_num = 2\n",
    "    \n",
    "    for line in lines:\n",
    "        curr_phone = line.split()\n",
    "        phone = curr_phone[0]\n",
    "        write_lines.append(\"{} {}\".format(phone, next_num))\n",
    "        next_num += 1\n",
    "        if \"vowel\" in curr_phone:\n",
    "            if phone not in ['yu', 'ai', 'ya', 'au']:\n",
    "                for ext_list in ve:\n",
    "                    ext = ext_list[0]\n",
    "                    phone_ext = phone + ext\n",
    "                    write_lines.append(\"{} {}\".format(phone_ext, next_num))\n",
    "                    next_num += 1\n",
    "                \n",
    "        elif \"consonant\" in curr_phone:\n",
    "            for ext_list in ce:\n",
    "                ext = ext_list[0]\n",
    "                phone_ext = phone + ext\n",
    "                write_lines.append(\"{} {}\".format(phone_ext, next_num))\n",
    "                next_num += 1\n",
    "                \n",
    "    # Special case of \"long\" applying to consonant\n",
    "    write_lines.append(\"J\\\\: {}\".format(next_num))\n",
    "                \n",
    "    if write_filepath is None:\n",
    "        write_filepath = join(os.getcwd(), \"universal_phones.txt\")\n",
    "        \n",
    "    with open(write_filepath, \"w\") as f:\n",
    "        print(\"Writing to {}\".format(write_filepath))\n",
    "        for line in write_lines:\n",
    "            f.write(line + \"\\n\")\n",
    "    return write_filepath\n",
    "            \n",
    "build_universal_phonemap(phones_filepath, ve, ce)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For universal phone stuff\n",
    "feats_filepath = join(conf_dir, \"articulatory_features\", \"feature_vectors.txt\")\n",
    "phones_list_filepath = join(os.getcwd(), \"universal_phones.txt\")\n",
    "phones_filepath = join(conf_dir, \"articulatory_features\", \"phone_attributes_filtered.txt\")\n",
    "phone_idx_dict = get_phone_idx_dict(phones_list_filepath)\n",
    "feat_idx_dict = get_feat_idx(feats_filepath)\n",
    "ve, ce = filter_valid_extensions(extensions_filepath, phone_idx_dict, feat_idx_dict)\n",
    "\n",
    "\n",
    "vp, cp = get_phones(phones_filepath, feat_idx_dict, phone_idx_dict, ve, ce)\n",
    "\n",
    "# Get tensor of consonants e.g [0 3 4 5 112 1] - avoids excessive converting to and from tensors\n",
    "cp_idx = [x[0] for x in cp]\n",
    "cp_idx = torch.from_numpy(np.asarray(cp_idx))\n",
    "\n",
    "# Get tensor of consonants e.g [0 3 4 5 112 1] - avoids excessive converting to and from tensors\n",
    "vp_idx = [x[0] for x in vp]\n",
    "vp_idx = torch.from_numpy(np.asarray(vp_idx))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "vp_ne, cp_ne = get_phones(phones_filepath, feat_idx_dict, phone_idx_dict, ve, ce, include_extensions=False)\n",
    "\n",
    "cp_idx_ne = [x[0] for x in cp_ne]\n",
    "cp_idx_ne = torch.from_numpy(np.asarray(cp_idx_ne))\n",
    "\n",
    "# Get tensor of consonants e.g [0 3 4 5 112 1] - avoids excessive converting to and from tensors\n",
    "vp_idx_ne = [x[0] for x in vp_ne]\n",
    "vp_idx_ne = torch.from_numpy(np.asarray(vp_idx_ne))\n",
    "\n",
    "save_variables(feat_idx_dict, vp_ne, cp_ne, vp_idx_ne, cp_idx_ne, filename=\"feat_vars_ne\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_variables(filename=None, load_dir=None):\n",
    "    if load_dir is None:\n",
    "        load_dir = os.getcwd()\n",
    "    if filename is None:\n",
    "        load_path = join(load_dir, \"feat_vars.pkl\")\n",
    "    else:\n",
    "        load_path = join(load_dir, filename + \".pkl\")\n",
    "    with open(load_path, 'rb') as f:\n",
    "        feat_idx_dict, vp, cp, vp_idx, cp_idx = pickle.load(f)\n",
    "    return feat_idx_dict, vp, cp, vp_idx, cp_idx\n",
    "\n",
    "feat_idx_dict, vp, cp, vp_idx, cp_idx = load_variables()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def convert_to_pred(out, feat_idx_dict, vp, cp, vp_idx, cp_idx):\n",
    "    # split into silence, vowels and consonants\n",
    "    vowel_idx = feat_idx_dict[\"vowel\"]\n",
    "    consonant_idx = feat_idx_dict[\"consonant\"]\n",
    "    vowels = out[:, vowel_idx]\n",
    "    consonants = out[:, consonant_idx]\n",
    "    sums = vowels + consonants\n",
    "    # There is roughly a 50% chance this phone is non-silence.\n",
    "    sum_bools = sums > 0.5\n",
    "    # Take max of vowel vs. consonant\n",
    "    vowel_bools = vowels > consonants\n",
    "    consonant_bools = ~vowel_bools\n",
    "    \n",
    "    vowel_idx = sum_bools & vowel_bools \n",
    "    consonant_idx = sum_bools & consonant_bools\n",
    "    silence_idx = ~sum_bools\n",
    "\n",
    "    vowels = out[vowel_idx]\n",
    "    consonants = out[consonant_idx]\n",
    "\n",
    "    # take the slice from [1:] (all the atts idx)\n",
    "    # sum the value of these attributes. \n",
    "    # divide by the number of attributes to normalise\n",
    "    v_scores = [vowels[:,slice_idx[1:]].sum(dim=1)/(len(slice_idx)-1) for slice_idx in vp]\n",
    "    # Stack to shape [29, N], where each 29 is the score for each vowel\n",
    "    v_scores = torch.stack(v_scores, dim=0)\n",
    "    # Get max phone idx, and convert this to the corresponding phone\n",
    "    v_out = vp_idx[v_scores.argmax(dim=0)] \n",
    "\n",
    "    c_scores = [consonants[:,slice_idx[1:]].sum(dim=1)/(len(slice_idx)-1) for slice_idx in cp]\n",
    "    # Stack to shape [86, N] where each 86 is the score for each consonant\n",
    "    c_scores = torch.stack(c_scores, dim=0)\n",
    "    c_out = cp_idx[c_scores.argmax(dim=0)]\n",
    "    \n",
    "    # Fill final output\n",
    "    final_out = torch.zeros(out.size()[0]).cuda()\n",
    "    final_out.masked_scatter_(consonant_idx, c_out.cuda().float())\n",
    "    final_out.masked_scatter_(vowel_idx, v_out.cuda().float())\n",
    "    final_out.masked_fill_(silence_idx, 1)\n",
    "    final_out = final_out.int()\n",
    "    \n",
    "    return final_out\n",
    "\n",
    "pred_2 = convert_to_pred(out, feat_idx_dict, vp, cp, vp_idx, cp_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([178,   1,   1, 196, 178, 196,   2, 196, 196,   1,   1, 196,   2, 196,\n",
       "          2, 196, 196,   1,   1,  60,   2, 196,   2,  16, 196,   1,   1,  60,\n",
       "          2,   2,   2,  16, 196,   1,   1,  60,   2,   2, 248, 196, 196,   1,\n",
       "          1,  60,   2,   2, 248, 196, 196,   1,   1,  60,   2,   2, 248, 196,\n",
       "        196,   1,   1,  60,   2,   2, 248, 196, 196,   1,   1,  16,   2,   2,\n",
       "        248,   2, 196,   1,   1,  16,   2,   2, 248,   2, 196,   1,   1,   2,\n",
       "          2,   2, 248,   2,  16,   1,   1,   2,   2,   2, 248,   2,  16,   1,\n",
       "          1,  60,   2,   2, 248,   2,  16,   1,   1,  16,   2,   2, 248,   2,\n",
       "         16,   1,   1,  16,   2,   2, 248,   2,  16,   1,   1,  16,   2,   2,\n",
       "        248,   2,  16,   1,   1,  16,   2,   2, 248, 110, 196,   1,   1,  16,\n",
       "          2,   2,   2, 110, 196,   1,   1,   2,   2, 110,   2, 110, 196,   1,\n",
       "          1,   2,   2, 110, 248, 196, 196,   1,   1,   2,   2, 110, 110, 196,\n",
       "        196,   1,   1,   2,   2,  16, 248, 178, 196,   1,  16,   2,   2,  16,\n",
       "        110,   2, 196,   1,  16,   2, 248, 196, 110,   2,   2,   1,  16,   2,\n",
       "        110, 196, 110, 196,   2,   1,  16,   2, 110,   2, 154, 196, 178,   1,\n",
       "          1,   2, 110,   2, 110,  16, 248,   1,   1,  60, 110,   2, 110, 196,\n",
       "        178,   1,   1,  60, 110,   2, 110, 196, 248,   1,   1,  60, 248,   2,\n",
       "        110,  16, 110,   1,   1,  16, 248,   2, 110, 196, 110, 110,   1,  16,\n",
       "        248,   2, 110, 196, 110, 178,   1,  16,   2,   2, 110, 196, 110, 196,\n",
       "          1,  16,   2,   2, 110,  16, 110, 196,   1,  60,   2,   2, 110,  16,\n",
       "         16,  16,   1,   2,   2,   2, 248,  16,  16,  16,   1,   2,   2,   2,\n",
       "          2, 196,  16,  16,   1,   2,   2,   2,   2, 196,  16,  16,   1,   2,\n",
       "          2,   2,   2, 196, 110,  16,   1,   2,   2,   2,   2, 196, 248,  16,\n",
       "          1,   2,   2,   2, 110, 196, 178,  16,   1,   2,   2,   2, 110, 196,\n",
       "          2,  16,   1,   2,   2,   2, 110, 196,   2,  16,   1,   2,   2,   2,\n",
       "        110, 196,   2,  16,   1,   2,   2,   2, 110, 196,   2,  16,   1,   2,\n",
       "          2,   2, 110, 196,   2,  16,   1,   2,   2,   2, 110, 196,   2,  16,\n",
       "          1,   2,   2,   2, 110, 196, 110, 196,   1,   2, 248,   2, 110, 196,\n",
       "        110, 196,   1, 248, 110, 110, 110, 196, 110, 178,   1, 248, 110, 110,\n",
       "        110, 196, 110, 178,   1, 248, 110, 110, 110, 196, 110, 178,   1,  16,\n",
       "          2,  16, 110, 196,  16, 248,   1,  16,   2,  16, 110, 196,  16, 248,\n",
       "          1,  16, 110,  16, 110, 196, 178, 110,   1,  16, 110,  16, 110, 196,\n",
       "        178,  16,   1,  16, 110, 196,  16, 196,   2,  16,   1,  60,  16, 196,\n",
       "         16, 196,   2,  16,   1,  60,  16,  16,  16, 196,   2,  16,   1,  16,\n",
       "         16,  16,  16, 196,   2,  16,   1,  16, 110,  16,  16, 196,  60,  16,\n",
       "          1,  16, 110,  16,  16, 196,  60,  16,   1,  16, 110,  16, 110, 196,\n",
       "         60,  16,   1,   2, 248,  16,  16, 196, 248,  16,   1,   2, 248,  16,\n",
       "         16, 196,  16,  16,   1,   2, 248, 178,  16, 196,  16,  16,   1, 178,\n",
       "        248, 178,  16, 196,  16,  16,   1, 178,   2, 178,  16,  16,  16,  16,\n",
       "          1,  16,   2, 178,  16,  16,  60,  16,   1,  16,   2,   2,  16,  16,\n",
       "        178,   1,   1, 196,   2,   2, 248,  16, 178,   1,   1, 178,   2, 196,\n",
       "        248,  16, 178,   1,   1, 178,   2, 196, 154,  16, 178,   1,   1,   2,\n",
       "          2, 196, 110,  16,  60,   1,   1,  60,   2, 196, 110,  16,  60,   1,\n",
       "          1,  60,   2, 196, 110, 196,  60,   1,   1,  60,   2, 196, 110, 196,\n",
       "         60,   1,   1,  16,   2, 196, 110, 196,  60,   1,   1,  60, 110,  60,\n",
       "         16, 196,  60,   1,   1,   2, 110,  60,  16,  60,  16,   1,   1,   2,\n",
       "        110,  60,  16,   2,  16,   1,   1,   2, 110,  60,  16,   2,  16,   1,\n",
       "          1,   2, 110,  60,  16,   2,  16,   1,   1,   2, 248,  60,  16,   2,\n",
       "        196,   1,   1,   2,   2,   2,  16,   2, 196,   1,   1,   2,   2,   2,\n",
       "        110,   2, 196,   1,   1,   2,   2,   2, 110,   2, 178,   1,   1,   2,\n",
       "          2,   2,  16,   2, 178,   1,   1,   2, 248,   2,  16,   2, 178,   1,\n",
       "          1,   2, 248,   2,  16,   2,   2,   1,   1,   2,   2,   2, 196,   2,\n",
       "          2,   1,   1,   2,   2, 248, 196, 248,   2,   1,   1,   2,   2, 248,\n",
       "        110, 178,   2,   1,   1,   2,   2, 248, 110, 178,   2,   1,   1,   1,\n",
       "          2, 248, 110,   2,   2,   1,   1,   1,   2, 248, 110,   2,   2,   1,\n",
       "          1,   1,   1, 248, 110,   2,   2,   1,   1,   1,   1, 248, 110,   2,\n",
       "          2,   1,   1,   1,   1,   2, 110,   2,   2,   1,   1,   1,   1,   2,\n",
       "        110,   2], device='cuda:0', dtype=torch.int32)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 89,   1,   1,  92,  89,  92,  34,  92,  92,   1,   1,  92,  34,  92,\n",
       "         34,  92,  92,   1,   1,  63,  34,  92,  34,  43,  92,   1,   1,  63,\n",
       "         34,  34,  34,  43,  92,   1,   1,  63,  34,  34, 114,  92,  92,   1,\n",
       "          1,  63,  34,  34, 114,  92,  92,   1,   1,  63,  34,  34, 114,  92,\n",
       "         92,   1,   1,  63,  34,  34, 114,  92,  92,   1,   1,  43,  34,  34,\n",
       "        114,  34,  92,   1,   1,  43,  34,  34, 114,  34,  92,   1,   1,  34,\n",
       "         34,  34, 114,  34,  43,   1,   1,  34,  34,  34, 114,  34,  43,   1,\n",
       "          1,  63,  34,  34, 114,  34,  43,   1,   1,  43,  34,  34, 114,  34,\n",
       "         43,   1,   1,  43,  34,  34, 114,  34,  43,   1,   1,  43,  34,  34,\n",
       "        114,  34,  43,   1,   1,  43,  34,  34, 114,  77,  92,   1,   1,  43,\n",
       "         34,  34,  34,  77,  92,   1,   1,  34,  34,  77,  34,  77,  92,   1,\n",
       "          1,  34,  34,  77, 114,  92,  92,   1,   1,  34,  34,  77,  77,  92,\n",
       "         92,   1,   1,  34,  34,  43, 114,  89,  92,   1,  43,  34,  34,  43,\n",
       "         77,  34,  92,   1,  43,  34, 114,  92,  77,  34,  34,   1,  43,  34,\n",
       "         77,  92,  77,  92,  34,   1,  43,  34,  77,  34,   0,  92,  89,   1,\n",
       "          1,  34,  77,  34,  77,  43, 114,   1,   1,  63,  77,  34,  77,  92,\n",
       "         89,   1,   1,  63,  77,  34,  77,  92, 114,   1,   1,  63, 114,  34,\n",
       "         77,  43,  77,   1,   1,  43, 114,  34,  77,  92,  77,  77,   1,  43,\n",
       "        114,  34,  77,  92,  77,  89,   1,  43,  34,  34,  77,  92,  77,  92,\n",
       "          1,  43,  34,  34,  77,  43,  77,  92,   1,  63,  34,  34,  77,  43,\n",
       "         43,  43,   1,  34,  34,  34, 114,  43,  43,  43,   1,  34,  34,  34,\n",
       "         34,  92,  43,  43,   1,  34,  34,  34,  34,  92,  43,  43,   1,  34,\n",
       "         34,  34,  34,  92,  77,  43,   1,  34,  34,  34,  34,  92, 114,  43,\n",
       "          1,  34,  34,  34,  77,  92,  89,  43,   1,  34,  34,  34,  77,  92,\n",
       "         34,  43,   1,  34,  34,  34,  77,  92,  34,  43,   1,  34,  34,  34,\n",
       "         77,  92,  34,  43,   1,  34,  34,  34,  77,  92,  34,  43,   1,  34,\n",
       "         34,  34,  77,  92,  34,  43,   1,  34,  34,  34,  77,  92,  34,  43,\n",
       "          1,  34,  34,  34,  77,  92,  77,  92,   1,  34, 114,  34,  77,  92,\n",
       "         77,  92,   1, 114,  77,  77,  77,  92,  77,  89,   1, 114,  77,  77,\n",
       "         77,  92,  77,  89,   1, 114,  77,  77,  77,  92,  77,  89,   1,  43,\n",
       "         34,  43,  77,  92,  43, 114,   1,  43,  34,  43,  77,  92,  43, 114,\n",
       "          1,  43,  77,  43,  77,  92,  89,  77,   1,  43,  77,  43,  77,  92,\n",
       "         89,  43,   1,  43,  77,  92,  43,  92,  34,  43,   1,  63,  43,  92,\n",
       "         43,  92,  34,  43,   1,  63,  43,  43,  43,  92,  34,  43,   1,  43,\n",
       "         43,  43,  43,  92,  34,  43,   1,  43,  77,  43,  43,  92,  63,  43,\n",
       "          1,  43,  77,  43,  43,  92,  63,  43,   1,  43,  77,  43,  77,  92,\n",
       "         63,  43,   1,  34, 114,  43,  43,  92, 114,  43,   1,  34, 114,  43,\n",
       "         43,  92,  43,  43,   1,  34, 114,  89,  43,  92,  43,  43,   1,  89,\n",
       "        114,  89,  43,  92,  43,  43,   1,  89,  34,  89,  43,  43,  43,  43,\n",
       "          1,  43,  34,  89,  43,  43,  63,  43,   1,  43,  34,  34,  43,  43,\n",
       "         89,   1,   1,  92,  34,  34, 114,  43,  89,   1,   1,  89,  34,  92,\n",
       "        114,  43,  89,   1,   1,  89,  34,  92,   0,  43,  89,   1,   1,  34,\n",
       "         34,  92,  77,  43,  63,   1,   1,  63,  34,  92,  77,  43,  63,   1,\n",
       "          1,  63,  34,  92,  77,  92,  63,   1,   1,  63,  34,  92,  77,  92,\n",
       "         63,   1,   1,  43,  34,  92,  77,  92,  63,   1,   1,  63,  77,  63,\n",
       "         43,  92,  63,   1,   1,  34,  77,  63,  43,  63,  43,   1,   1,  34,\n",
       "         77,  63,  43,  34,  43,   1,   1,  34,  77,  63,  43,  34,  43,   1,\n",
       "          1,  34,  77,  63,  43,  34,  43,   1,   1,  34, 114,  63,  43,  34,\n",
       "         92,   1,   1,  34,  34,  34,  43,  34,  92,   1,   1,  34,  34,  34,\n",
       "         77,  34,  92,   1,   1,  34,  34,  34,  77,  34,  89,   1,   1,  34,\n",
       "         34,  34,  43,  34,  89,   1,   1,  34, 114,  34,  43,  34,  89,   1,\n",
       "          1,  34, 114,  34,  43,  34,  34,   1,   1,  34,  34,  34,  92,  34,\n",
       "         34,   1,   1,  34,  34, 114,  92, 114,  34,   1,   1,  34,  34, 114,\n",
       "         77,  89,  34,   1,   1,  34,  34, 114,  77,  89,  34,   1,   1,   1,\n",
       "         34, 114,  77,  34,  34,   1,   1,   1,  34, 114,  77,  34,  34,   1,\n",
       "          1,   1,   1, 114,  77,  34,  34,   1,   1,   1,   1, 114,  77,  34,\n",
       "         34,   1,   1,   1,   1,  34,  77,  34,  34,   1,   1,   1,   1,  34,\n",
       "         77,  34], device='cuda:0', dtype=torch.int32)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Takes max value for the zero (unknown) phone\n",
    "def reduce_zeros(scores, idx):\n",
    "    zero_idx = idx == 0\n",
    "    zero_count = zero_idx.sum()\n",
    "        \n",
    "    zero = torch.zeros(1)\n",
    "        \n",
    "    # Only keep highest zero-score\n",
    "    max_zero_score = scores[zero_idx].max(axis=0)[0]\n",
    "    # Add 1-dim for concatenation\n",
    "    max_zero_score.unsqueeze_(0)\n",
    "\n",
    "    # filter out the original zero rows\n",
    "    scores_out = torch.cat((max_zero_score, scores[~zero_idx,:]), 0).cuda()\n",
    "    idx_out = torch.cat((zero, idx[~zero_idx].float())).cuda()\n",
    "        \n",
    "    # idx_out is now [0, x, y, ...]\n",
    "    # scores_out is now [zero_scores, x_scores, y_scores, ...]\n",
    "    # zero_scores is the mean zero (unknown) score\n",
    "    return scores_out, idx_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0004, device='cuda:0', grad_fn=<SelectBackward>)\n"
     ]
    }
   ],
   "source": [
    "def convert_to_scores(out, feat_idx_dict, phone_idx_dict, vp, cp, vp_idx, cp_idx):\n",
    "    # split into silence, vowels and consonants\n",
    "    vowel_idx = feat_idx_dict[\"vowel\"]\n",
    "    consonant_idx = feat_idx_dict[\"consonant\"]\n",
    "    vowels = out[:, vowel_idx]\n",
    "    consonants = out[:, consonant_idx]\n",
    "    sums = vowels + consonants\n",
    "    # There is roughly a 50% chance this phone is non-silence.\n",
    "    sum_bools = sums > 0.5\n",
    "    # Take max of vowel vs. consonant\n",
    "    vowel_bools = vowels > consonants\n",
    "    consonant_bools = ~vowel_bools\n",
    "    \n",
    "    vowel_idx = sum_bools & vowel_bools \n",
    "    consonant_idx = sum_bools & consonant_bools\n",
    "    silence_idx = ~sum_bools\n",
    "\n",
    "    vowels = out[vowel_idx]\n",
    "    consonants = out[consonant_idx]\n",
    "    \n",
    "    n_phones = len(phone_idx_dict)\n",
    "    \n",
    "    # Output is N x #phones\n",
    "    out_scores = torch.zeros((out.size()[0], n_phones))\n",
    "    \n",
    "    combined_v_scores = get_all_phone_scores(vowels, vp, vp_idx, n_phones)\n",
    "    combined_c_scores = get_all_phone_scores(consonants, cp, cp_idx, n_phones)\n",
    "\n",
    "    # Fill final output\n",
    "    final_out = torch.zeros((out.size()[0], n_phones)).cuda()\n",
    "    final_out[consonant_idx,:] =  combined_c_scores\n",
    "    final_out[vowel_idx,:] = combined_v_scores\n",
    "    \n",
    "    silence_sum = sums[silence_idx]  # Will be values < 0.5\n",
    "    silence_prob = 1 - silence_sum # Will be values > 0.5\n",
    "    non_silence_probs = silence_sum / (n_phones) # Distribute likelihood of non-silence across attributes \n",
    "    non_silence_probs.unsqueeze_(dim=1)\n",
    "    final_out[silence_idx,:] =  non_silence_probs.repeat(1, n_phones)\n",
    "    \n",
    "    final_out[silence_idx,1] = torch.exp(1 - sums[silence_idx])  # Fill the silent indices with the probability they were silence\n",
    "    final_out = final_out.cuda()\n",
    "    \n",
    "    final_out[final_out == 0] = -math.inf\n",
    "    final_out = softmax(final_out, dim=1)\n",
    "    return final_out\n",
    "\n",
    "def get_all_phone_scores(out, phones, phone_idx, total_seen_phones):\n",
    "    # take the slice from [1:] (all the atts idx)\n",
    "    # sum the value of these attributes. \n",
    "    # divide by the number of attributes to normalise\n",
    "    scores = [out[:,slice_idx[1:]].sum(dim=1)/(len(slice_idx)-1) for slice_idx in phones]\n",
    "    # Stack to shape [# vowel phones, N]\n",
    "    scores = torch.stack(scores, dim=0)\n",
    "    n = scores.shape[1]\n",
    "    \n",
    "    scores, phone_idx = reduce_zeros(scores, phone_idx)\n",
    "    \n",
    "    combined_scores = torch.zeros((n, total_seen_phones))\n",
    "    for idx, col_idx in enumerate(phone_idx.long()):\n",
    "        combined_scores[:,col_idx] = scores[idx,:]\n",
    "        \n",
    "    return combined_scores.cuda()\n",
    "        \n",
    "final_out_2 = convert_to_scores(out, feat_idx_dict, phone_idx_dict, vp, cp, vp_idx, cp_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([800, 122])"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_out_2.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr = final_out_2.detach().cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.01377007, 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.00735575, 0.10995455, 0.00735575, ..., 0.00735575, 0.00735575,\n",
       "        0.00735575],\n",
       "       [0.00763683, 0.07594381, 0.00763683, ..., 0.00763683, 0.00763683,\n",
       "        0.00763683],\n",
       "       ...,\n",
       "       [0.03710816, 0.        , 0.        , ..., 0.02822955, 0.        ,\n",
       "        0.        ],\n",
       "       [0.0138104 , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.03635043, 0.        , 0.        , ..., 0.02937838, 0.        ,\n",
       "        0.        ]], dtype=float32)"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 89,   1,   1,  92,  89,  92,  34,  92,  92,   1,   1,  92,  34,  92,\n",
       "         34,  92,  92,   1,   1,  63,  34,  92,  34,  43,  92,   1,   1,  63,\n",
       "         34,  34,  34,  43,  92,   1,   1,  63,  34,  34, 114,  92,  92,   1,\n",
       "          1,  63,  34,  34, 114,  92,  92,   1,   1,  63,  34,  34, 114,  92,\n",
       "         92,   1,   1,  63,  34,  34, 114,  92,  92,   1,   1,  43,  34,  34,\n",
       "        114,  34,  92,   1,   1,  43,  34,  34, 114,  34,  92,   1,   1,  34,\n",
       "         34,  34, 114,  34,  43,   1,   1,  34,  34,  34, 114,  34,  43,   1,\n",
       "          1,  63,  34,  34, 114,  34,  43,   1,   1,  43,  34,  34, 114,  34,\n",
       "         43,   1,   1,  43,  34,  34, 114,  34,  43,   1,   1,  43,  34,  34,\n",
       "        114,  34,  43,   1,   1,  43,  34,  34, 114,  77,  92,   1,   1,  43,\n",
       "         34,  34,  34,  77,  92,   1,   1,  34,  34,  77,  34,  77,  92,   1,\n",
       "          1,  34,  34,  77, 114,  92,  92,   1,   1,  34,  34,  77,  77,  92,\n",
       "         92,   1,   1,  34,  34,  43, 114,  89,  92,   1,  43,  34,  34,  43,\n",
       "         77,  34,  92,   1,  43,  34, 114,  92,  77,  34,  34,   1,  43,  34,\n",
       "         77,  92,  77,  92,  34,   1,  43,  34,  77,  34,   0,  92,  89,   1,\n",
       "          1,  34,  77,  34,  77,  43, 114,   1,   1,  63,  77,  34,  77,  92,\n",
       "         89,   1,   1,  63,  77,  34,  77,  92, 114,   1,   1,  63, 114,  34,\n",
       "         77,  43,  77,   1,   1,  43, 114,  34,  77,  92,  77,  77,   1,  43,\n",
       "        114,  34,  77,  92,  77,  89,   1,  43,  34,  34,  77,  92,  77,  92,\n",
       "          1,  43,  34,  34,  77,  43,  77,  92,   1,  63,  34,  34,  77,  43,\n",
       "         43,  43,   1,  34,  34,  34, 114,  43,  43,  43,   1,  34,  34,  34,\n",
       "         34,  92,  43,  43,   1,  34,  34,  34,  34,  92,  43,  43,   1,  34,\n",
       "         34,  34,  34,  92,  77,  43,   1,  34,  34,  34,  34,  92, 114,  43,\n",
       "          1,  34,  34,  34,  77,  92,  89,  43,   1,  34,  34,  34,  77,  92,\n",
       "         34,  43,   1,  34,  34,  34,  77,  92,  34,  43,   1,  34,  34,  34,\n",
       "         77,  92,  34,  43,   1,  34,  34,  34,  77,  92,  34,  43,   1,  34,\n",
       "         34,  34,  77,  92,  34,  43,   1,  34,  34,  34,  77,  92,  34,  43,\n",
       "          1,  34,  34,  34,  77,  92,  77,  92,   1,  34, 114,  34,  77,  92,\n",
       "         77,  92,   1, 114,  77,  77,  77,  92,  77,  89,   1, 114,  77,  77,\n",
       "         77,  92,  77,  89,   1, 114,  77,  77,  77,  92,  77,  89,   1,  43,\n",
       "         34,  43,  77,  92,  43, 114,   1,  43,  34,  43,  77,  92,  43, 114,\n",
       "          1,  43,  77,  43,  77,  92,  89,  77,   1,  43,  77,  43,  77,  92,\n",
       "         89,  43,   1,  43,  77,  92,  43,  92,  34,  43,   1,  63,  43,  92,\n",
       "         43,  92,  34,  43,   1,  63,  43,  43,  43,  92,  34,  43,   1,  43,\n",
       "         43,  43,  43,  92,  34,  43,   1,  43,  77,  43,  43,  92,  63,  43,\n",
       "          1,  43,  77,  43,  43,  92,  63,  43,   1,  43,  77,  43,  77,  92,\n",
       "         63,  43,   1,  34, 114,  43,  43,  92, 114,  43,   1,  34, 114,  43,\n",
       "         43,  92,  43,  43,   1,  34, 114,  89,  43,  92,  43,  43,   1,  89,\n",
       "        114,  89,  43,  92,  43,  43,   1,  89,  34,  89,  43,  43,  43,  43,\n",
       "          1,  43,  34,  89,  43,  43,  63,  43,   1,  43,  34,  34,  43,  43,\n",
       "         89,   1,   1,  92,  34,  34, 114,  43,  89,   1,   1,  89,  34,  92,\n",
       "        114,  43,  89,   1,   1,  89,  34,  92,   0,  43,  89,   1,   1,  34,\n",
       "         34,  92,  77,  43,  63,   1,   1,  63,  34,  92,  77,  43,  63,   1,\n",
       "          1,  63,  34,  92,  77,  92,  63,   1,   1,  63,  34,  92,  77,  92,\n",
       "         63,   1,   1,  43,  34,  92,  77,  92,  63,   1,   1,  63,  77,  63,\n",
       "         43,  92,  63,   1,   1,  34,  77,  63,  43,  63,  43,   1,   1,  34,\n",
       "         77,  63,  43,  34,  43,   1,   1,  34,  77,  63,  43,  34,  43,   1,\n",
       "          1,  34,  77,  63,  43,  34,  43,   1,   1,  34, 114,  63,  43,  34,\n",
       "         92,   1,   1,  34,  34,  34,  43,  34,  92,   1,   1,  34,  34,  34,\n",
       "         77,  34,  92,   1,   1,  34,  34,  34,  77,  34,  89,   1,   1,  34,\n",
       "         34,  34,  43,  34,  89,   1,   1,  34, 114,  34,  43,  34,  89,   1,\n",
       "          1,  34, 114,  34,  43,  34,  34,   1,   1,  34,  34,  34,  92,  34,\n",
       "         34,   1,   1,  34,  34, 114,  92, 114,  34,   1,   1,  34,  34, 114,\n",
       "         77,  89,  34,   1,   1,  34,  34, 114,  77,  89,  34,   1,   1,   1,\n",
       "         34, 114,  77,  34,  34,   1,   1,   1,  34, 114,  77,  34,  34,   1,\n",
       "          1,   1,   1, 114,  77,  34,  34,   1,   1,   1,   1, 114,  77,  34,\n",
       "         34,   1,   1,   1,   1,  34,  77,  34,  34,   1,   1,   1,   1,  34,\n",
       "         77,  34], device='cuda:0')"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_out_2.argmax(dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([  0,   1,  34,  43,  63,  77,  89,  92, 114], device='cuda:0'),\n",
       " tensor([  2, 167, 214, 128,  34,  86,  29,  93,  47], device='cuda:0'))"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_out_2.argmax(dim=1).unique(return_counts =True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_idx = torch.cat((vp_idx, cp_idx))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([563])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_idx.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_p = np.concatenate((vp, cp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "563"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(all_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0.,  ..., 0., 1., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 1., 0., 0.],\n",
       "        [0., 1., 0.,  ..., 1., 0., 0.]], device='cuda:0')"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_softmax(out, feat_idx_dict, phone_idx_dict, all_p, all_idx):\n",
    "    n_phones = len(phone_idx_dict)\n",
    "    n_phones_full = len(all_idx)\n",
    "    n = out.size()[0]\n",
    "    \n",
    "    vowel_idx = feat_idx_dict[\"vowel\"]\n",
    "    consonant_idx = feat_idx_dict[\"consonant\"]\n",
    "    vowels = out[:, vowel_idx]\n",
    "    consonants = out[:, consonant_idx]\n",
    "    sums = vowels + consonants\n",
    "    # There is roughly a 50% chance this phone is non-silence.\n",
    "    sum_bools = sums > 0.5\n",
    "    # Take max of vowel vs. consonant\n",
    "    silence_idx = ~sum_bools\n",
    "    \n",
    "    phones = out[sum_bools]\n",
    "    \n",
    "    # Output is N x #phones\n",
    "    final_out = torch.zeros((out.size()[0], n_phones))\n",
    "    \n",
    "    all_scores = [phones[:,slice_idx[1:]].sum(dim=1)/(len(slice_idx)-1) for slice_idx in all_p]\n",
    "    all_scores = torch.stack(all_scores, dim=0)\n",
    "    \n",
    "    zero_idx = all_idx == 0\n",
    "    zero_count = zero_idx.sum()\n",
    "    if zero_count > 1: # Need to combine multiple 0 outputs\n",
    "        # Only keep highest zero-score\n",
    "        max_zero_score = all_scores[zero_idx].max(axis=0)[0]\n",
    "        # Add 1-dim for concatenation\n",
    "        max_zero_score.unsqueeze_(0)\n",
    "\n",
    "        # filter out the original zero rows\n",
    "        all_scores = torch.cat((max_zero_score, all_scores[~zero_idx,:]), 0).cuda()\n",
    "        zero = torch.zeros(1)\n",
    "        all_idx = torch.cat((zero, all_idx[~zero_idx].float())).cuda().long()\n",
    "    \n",
    "    lang_scores = torch.zeros((all_scores.shape[1], n_phones))\n",
    "    for idx, col_idx in enumerate(all_idx.long()):\n",
    "        lang_scores[:,col_idx] = all_scores[idx,:]\n",
    "    \n",
    "    final_out[sum_bools] = lang_scores\n",
    "    final_out[silence_idx,1] = 1\n",
    "    # Set zero scores to -inf for softmax\n",
    "    final_out[final_out == 0] = -math.inf\n",
    "    final_out = softmax(final_out, dim=1)\n",
    "#     for row_idx, phone_idx in enumerate(all_idx):\n",
    "#         final_out[sum_bools][phone_idx] = all_scores[row_idx,:]\n",
    "    #final_out.masked_scatter()\n",
    "    \n",
    "    # Add prediction for silence\n",
    "    # Get normalised total across all attributes. 1 - total = score for silence \n",
    "    #silence_score = 1 - (out.sum(axis=1)/(out.size()[1]))\n",
    "    #final_out[:,1] = silence_score\n",
    "    \n",
    "    return final_out\n",
    "\n",
    "final_out = convert_to_softmax(out, feat_idx_dict, phone_idx_dict, all_p, all_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([63,  1,  1, 63, 34, 92, 34, 63, 63,  1,  1, 63, 34, 63, 34, 63, 63,  1,\n",
       "         1, 63, 34, 63, 34, 63, 63,  1,  1, 63, 34, 34, 34, 63, 63,  1,  1, 63,\n",
       "        34, 34, 34, 63, 63,  1,  1, 63, 34, 34, 34, 63, 63,  1,  1, 63, 34, 34,\n",
       "        34, 63, 63,  1,  1, 63, 34, 34, 34, 34, 63,  1,  1, 63, 34, 34, 34, 34,\n",
       "        63,  1,  1, 34, 34, 34, 34, 34, 63,  1,  1, 34, 34, 34, 34, 34, 63,  1,\n",
       "         1, 34, 34, 34, 34, 34, 63,  1,  1, 63, 34, 34, 34, 34, 63,  1,  1, 63,\n",
       "        34, 34, 34, 34, 63,  1,  1, 63, 34, 34, 34, 34, 63,  1,  1, 63, 34, 34,\n",
       "        34, 34, 63,  1,  1, 63, 34, 34, 34, 34, 63,  1,  1, 63, 34, 34, 34, 34,\n",
       "        63,  1,  1, 34, 34, 34, 34, 34, 63,  1,  1, 34, 34, 34, 34, 34, 63,  1,\n",
       "         1, 34, 34, 34, 34, 34, 63,  1,  1, 34, 34, 43, 34, 34, 63,  1, 63, 34,\n",
       "        34, 63, 34, 34, 63,  1, 63, 34, 34, 34, 34, 34, 34,  1, 63, 34, 34, 34,\n",
       "        34, 63, 34,  1, 63, 34, 34, 34, 34, 63, 34,  1,  1, 34, 34, 34, 34, 63,\n",
       "        34,  1,  1, 63, 34, 34, 34, 63, 34,  1,  1, 63, 34, 34, 34, 63, 34,  1,\n",
       "         1, 63, 34, 34, 34, 63, 34,  1,  1, 63, 34, 34, 77, 63, 63, 63,  1, 63,\n",
       "        34, 34, 77, 63, 63, 63,  1, 63, 34, 34,  0, 63, 63, 63,  1, 63, 34, 34,\n",
       "        63, 63, 63, 63,  1, 63, 34, 34, 34, 43, 63, 63,  1, 34, 34, 34, 34, 43,\n",
       "        63, 63,  1, 34, 34, 34, 34, 63, 63, 63,  1, 34, 34, 34, 34, 34, 63, 63,\n",
       "         1, 34, 34, 34, 34, 34, 63, 63,  1, 34, 34, 34, 34, 34, 63, 63,  1, 34,\n",
       "        34, 34, 34, 34, 34, 63,  1, 34, 34, 34, 34, 34, 34, 63,  1, 34, 34, 34,\n",
       "        34, 63, 34, 43,  1, 34, 34, 34, 34, 63, 34, 63,  1, 34, 34, 34, 34, 63,\n",
       "        34, 63,  1, 34, 34, 34, 34, 63, 34, 63,  1, 34, 34, 34, 34, 63, 34, 63,\n",
       "         1, 34, 34, 34, 34, 92, 34, 63,  1, 34, 34, 34, 34, 92, 63, 63,  1, 34,\n",
       "        34, 34, 34, 63, 63, 63,  1, 34, 34, 34, 63, 63, 63, 63,  1, 63, 34, 34,\n",
       "        34, 63, 63, 63,  1, 63, 34, 63, 34, 63, 63, 63,  1, 63, 34, 63, 34, 63,\n",
       "        63, 63,  1, 63, 34, 63, 34, 63, 63, 63,  1, 63, 34, 63,  0, 63, 34, 63,\n",
       "         1, 63, 34, 63, 43, 63, 34, 63,  1, 63, 43, 63, 43, 63, 34, 63,  1, 63,\n",
       "        63, 63, 43, 92, 34, 63,  1, 63, 63, 63, 43, 63, 34, 63,  1, 63, 63, 63,\n",
       "        63, 63, 63, 63,  1, 63, 34, 63, 63, 63, 63, 63,  1, 34, 34, 63, 63, 63,\n",
       "        63, 63,  1, 34, 34, 63, 63, 63, 63, 63,  1, 34, 34, 34, 63, 63, 63, 63,\n",
       "         1, 34, 34, 34, 63, 63, 63, 63,  1, 34, 34, 34, 63, 63, 63, 63,  1, 34,\n",
       "        34, 34, 63, 63, 63, 63,  1, 63, 34, 34, 63, 63, 63, 63,  1, 63, 34, 34,\n",
       "        63, 63, 63,  1,  1, 63, 34, 34, 34, 63, 63,  1,  1, 34, 34, 34, 34, 63,\n",
       "        63,  1,  1, 34, 34, 63, 34, 63, 63,  1,  1, 34, 34, 63, 34, 63, 63,  1,\n",
       "         1, 63, 34, 63, 34, 63, 63,  1,  1, 63, 34, 63, 34, 63, 63,  1,  1, 63,\n",
       "        34, 63, 34, 63, 63,  1,  1, 63, 34, 63, 77, 63, 63,  1,  1, 63, 34, 63,\n",
       "        43, 63, 63,  1,  1, 34, 34, 63, 43, 63, 63,  1,  1, 34, 34, 63, 43, 34,\n",
       "        63,  1,  1, 34, 34, 63, 43, 34, 63,  1,  1, 34, 34, 63, 63, 34, 63,  1,\n",
       "         1, 34, 34, 63, 63, 34, 63,  1,  1, 34, 34, 34, 63, 34, 63,  1,  1, 34,\n",
       "        34, 34, 63, 34, 63,  1,  1, 34, 34, 34, 63, 34, 63,  1,  1, 34, 34, 34,\n",
       "        43, 34, 63,  1,  1, 34, 34, 34, 43, 34, 63,  1,  1, 34, 34, 34, 43, 34,\n",
       "        34,  1,  1, 34, 34, 34, 63, 34, 34,  1,  1, 34, 34, 34, 34, 34, 34,  1,\n",
       "         1, 34, 34, 34, 34, 34, 34,  1,  1, 34, 34, 34, 34, 34, 34,  1,  1,  1,\n",
       "        34, 34, 34, 34, 34,  1,  1,  1, 34, 34, 34, 34, 34,  1,  1,  1,  1, 34,\n",
       "        34, 34, 34,  1,  1,  1,  1, 34, 34, 34, 34,  1,  1,  1,  1, 34, 34, 34,\n",
       "        34,  1,  1,  1,  1, 34, 63, 34])"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_out.argmax(dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "true = mapping_to_labels(mapping, lab_dnn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([  1.,   5.,  14.,  15.,  26.,  34.,  41.,  59.,  60.,  63.,  65.,\n",
       "         68.,  72.,  75.,  77.,  82.,  89.,  92., 100., 107., 114., 116.]),\n",
       " array([165,   6,   3,  48,  17, 136,  10,  23,  16,  70,  46,  49,  21,\n",
       "         26,  27,   3,  41,   6,  44,   9,  17,  17], dtype=int64))"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(true, return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "test[test == 0] = -math.inf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "soft2 = softmax(test, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([ 0, 34, 43, 63, 77, 92]), tensor([  2, 510,  16, 265,   3,   4]))"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds.unique(return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([63, 34, 34, 63, 34, 92, 34, 63, 63, 34, 34, 63, 34, 63, 34, 63, 63, 34,\n",
       "        34, 63, 34, 63, 34, 63, 63, 34, 34, 63, 34, 34, 34, 63, 63, 34, 34, 63,\n",
       "        34, 34, 34, 63, 63, 34, 34, 63, 34, 34, 34, 63, 63, 34, 34, 63, 34, 34,\n",
       "        34, 63, 63, 34, 34, 63, 34, 34, 34, 34, 63, 34, 34, 63, 34, 34, 34, 34,\n",
       "        63, 34, 34, 34, 34, 34, 34, 34, 63, 34, 34, 34, 34, 34, 34, 34, 63, 34,\n",
       "        34, 34, 34, 34, 34, 34, 63, 34, 34, 63, 34, 34, 34, 34, 63, 34, 34, 63,\n",
       "        34, 34, 34, 34, 63, 34, 34, 63, 34, 34, 34, 34, 63, 34, 34, 63, 34, 34,\n",
       "        34, 34, 63, 34, 34, 63, 34, 34, 34, 34, 63, 34, 34, 63, 34, 34, 34, 34,\n",
       "        63, 34, 34, 34, 34, 34, 34, 34, 63, 34, 34, 34, 34, 34, 34, 34, 63, 34,\n",
       "        63, 34, 34, 34, 34, 34, 63, 34, 63, 34, 34, 43, 34, 34, 63, 34, 63, 34,\n",
       "        34, 63, 34, 34, 63, 34, 63, 34, 34, 34, 34, 34, 34, 34, 63, 34, 34, 34,\n",
       "        34, 63, 34, 34, 63, 34, 34, 34, 34, 63, 34, 34, 63, 34, 34, 34, 34, 63,\n",
       "        34, 34, 63, 63, 34, 34, 34, 63, 34, 34, 34, 63, 34, 34, 34, 63, 34, 34,\n",
       "        34, 63, 34, 34, 34, 63, 34, 63, 34, 63, 34, 34, 77, 63, 63, 63, 34, 63,\n",
       "        34, 34, 77, 63, 63, 63, 34, 63, 34, 34,  0, 63, 63, 63, 34, 63, 34, 34,\n",
       "        63, 63, 63, 63, 34, 63, 34, 34, 34, 43, 63, 63, 34, 34, 34, 34, 34, 43,\n",
       "        63, 63, 34, 34, 34, 34, 34, 63, 63, 63, 34, 34, 34, 34, 34, 34, 63, 63,\n",
       "        34, 34, 34, 34, 34, 34, 63, 63, 34, 34, 34, 34, 34, 34, 63, 63, 34, 34,\n",
       "        34, 34, 34, 34, 34, 63, 34, 34, 34, 34, 34, 34, 34, 63, 34, 34, 34, 34,\n",
       "        34, 63, 34, 43, 34, 34, 34, 34, 34, 63, 34, 63, 34, 34, 34, 34, 34, 63,\n",
       "        34, 63, 34, 34, 34, 34, 34, 63, 34, 63, 34, 34, 34, 34, 34, 63, 34, 63,\n",
       "        34, 34, 34, 34, 34, 92, 34, 63, 34, 34, 34, 34, 34, 92, 63, 63, 34, 34,\n",
       "        34, 34, 34, 63, 63, 63, 34, 34, 34, 34, 63, 63, 63, 63, 34, 63, 34, 34,\n",
       "        34, 63, 63, 63, 34, 63, 34, 63, 34, 63, 63, 63, 34, 63, 34, 63, 34, 63,\n",
       "        63, 63, 34, 63, 34, 63, 34, 63, 63, 63, 34, 63, 34, 63,  0, 63, 34, 63,\n",
       "        34, 63, 34, 63, 43, 63, 34, 63, 34, 63, 43, 63, 43, 63, 34, 63, 34, 63,\n",
       "        63, 63, 43, 92, 34, 63, 34, 63, 63, 63, 43, 63, 34, 63, 34, 63, 63, 63,\n",
       "        63, 63, 63, 63, 34, 63, 34, 63, 63, 63, 63, 63, 34, 34, 34, 63, 63, 63,\n",
       "        63, 63, 34, 34, 34, 63, 63, 63, 63, 63, 34, 34, 34, 34, 63, 63, 63, 63,\n",
       "        34, 34, 34, 34, 63, 63, 63, 63, 34, 34, 34, 34, 63, 63, 63, 63, 34, 34,\n",
       "        34, 34, 63, 63, 63, 63, 34, 63, 34, 34, 63, 63, 63, 63, 34, 63, 34, 34,\n",
       "        63, 63, 63, 63, 34, 63, 34, 34, 34, 63, 63, 63, 34, 34, 34, 34, 34, 63,\n",
       "        63, 63, 34, 34, 34, 63, 34, 63, 63, 63, 34, 34, 34, 63, 34, 63, 63, 34,\n",
       "        34, 63, 34, 63, 34, 63, 63, 34, 34, 63, 34, 63, 34, 63, 63, 34, 34, 63,\n",
       "        34, 63, 34, 63, 63, 34, 34, 63, 34, 63, 77, 63, 63, 34, 34, 63, 34, 63,\n",
       "        43, 63, 63, 34, 34, 34, 34, 63, 43, 63, 63, 34, 34, 34, 34, 63, 43, 34,\n",
       "        63, 34, 34, 34, 34, 63, 43, 34, 63, 34, 34, 34, 34, 63, 63, 34, 63, 34,\n",
       "        34, 34, 34, 63, 63, 34, 63, 34, 34, 34, 34, 34, 63, 34, 63, 34, 34, 34,\n",
       "        34, 34, 63, 34, 63, 34, 34, 34, 34, 34, 63, 34, 63, 34, 34, 34, 34, 34,\n",
       "        43, 34, 63, 34, 34, 34, 34, 34, 43, 34, 63, 34, 34, 34, 34, 34, 43, 34,\n",
       "        34, 34, 34, 34, 34, 34, 63, 34, 34, 34, 34, 34, 34, 34, 34, 34, 34, 34,\n",
       "        34, 34, 34, 34, 34, 34, 34, 34, 34, 34, 34, 34, 34, 34, 34, 34, 34, 34,\n",
       "        34, 34, 34, 34, 34, 34, 34, 34, 34, 34, 34, 34, 34, 34, 34, 34, 34, 34,\n",
       "        34, 34, 34, 34, 34, 34, 34, 34, 34, 34, 34, 34, 34, 34, 34, 34, 34, 34,\n",
       "        34, 34, 34, 34, 34, 34, 63, 34])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_out.argmax(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "softy = softmax(final_out, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.0760, 0.0000, 0.0000, 0.0582, 0.0579, 0.0327, 0.0538, 0.0628, 0.0503,\n",
       "        0.0199, 0.0405, 0.0718, 0.0575, 0.0327, 0.0305, 0.0838, 0.0671, 0.0000,\n",
       "        0.0300, 0.0790, 0.0319, 0.0284, 0.0118, 0.0260, 0.0609, 0.0291, 0.0377,\n",
       "        0.0000, 0.0317, 0.0274, 0.0308, 0.0328, 0.0313, 0.0271, 0.0970, 0.0776,\n",
       "        0.0000, 0.0000, 0.0293, 0.0252, 0.0253, 0.0000, 0.0249, 0.0340, 0.0268,\n",
       "        0.0291, 0.0293, 0.0252, 0.0273, 0.0326, 0.0281, 0.0000, 0.0789, 0.0632,\n",
       "        0.0312, 0.0270, 0.0269, 0.0232, 0.0234, 0.0000, 0.0321, 0.0317, 0.0265,\n",
       "        0.0860, 0.0689, 0.0293, 0.0253, 0.0000, 0.0272, 0.0227, 0.0227, 0.0236,\n",
       "        0.0324, 0.0286, 0.0268, 0.0332, 0.0277, 0.0371, 0.0319, 0.0297, 0.0328,\n",
       "        0.0263, 0.0304, 0.0335, 0.0263, 0.0322, 0.0313, 0.0269, 0.0244, 0.0374,\n",
       "        0.0322, 0.0308, 0.0343, 0.0272, 0.0236, 0.0296, 0.0263, 0.0277, 0.0329,\n",
       "        0.0284, 0.0399, 0.0319, 0.0309, 0.0327, 0.0273, 0.0267, 0.0000, 0.0323,\n",
       "        0.0303, 0.0262, 0.0651, 0.0521, 0.0000, 0.0000, 0.0371, 0.0319, 0.0000,\n",
       "        0.0789, 0.0632, 0.0298, 0.0000, 0.0000], grad_fn=<SliceBackward>)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_out[2,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.0087, grad_fn=<SelectBackward>)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "softy[2,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0089, 0.0066, 0.0066,  ..., 0.0078, 0.0066, 0.0066],\n",
       "        [0.0082, 0.0082, 0.0082,  ..., 0.0082, 0.0082, 0.0082],\n",
       "        [0.0086, 0.0079, 0.0079,  ..., 0.0082, 0.0079, 0.0079],\n",
       "        ...,\n",
       "        [0.0098, 0.0066, 0.0066,  ..., 0.0078, 0.0066, 0.0066],\n",
       "        [0.0089, 0.0068, 0.0068,  ..., 0.0078, 0.0068, 0.0068],\n",
       "        [0.0093, 0.0070, 0.0070,  ..., 0.0078, 0.0070, 0.0070]],\n",
       "       grad_fn=<SoftmaxBackward>)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "softy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "122"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(phone_idx_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_out = torch.zeros((out.size()[0], 122)).cuda()\n",
    "dummy = torch.ones((107,800)).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "invalid argument 3: Index tensor must be either empty or have same dimensions as input tensor at C:/w/1/s/tmp_conda_3.7_100118/conda/conda-bld/pytorch_1579082551706/work/aten/src\\THC/generic/THCTensorScatterGather.cu:115",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-58-f17e289249dd>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mfinal_out\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscatter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mall_idx_2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlong\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdummy\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m: invalid argument 3: Index tensor must be either empty or have same dimensions as input tensor at C:/w/1/s/tmp_conda_3.7_100118/conda/conda-bld/pytorch_1579082551706/work/aten/src\\THC/generic/THCTensorScatterGather.cu:115"
     ]
    }
   ],
   "source": [
    "final_out.scatter(1, all_idx_2.long(), dummy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    v_scores = [vowels[:,slice_idx[1:]].sum(dim=1)/(len(slice_idx)-1) for slice_idx in vp]\n",
    "    # Stack to shape [29, N], where each 29 is the score for each vowel\n",
    "    v_scores = torch.stack(v_scores, dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "phone_nums = [x[0] for x in all_p]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique = list(set(list(phone_nums)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([800, 122])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def check_sums(tensor_list, target_sum=None):\n",
    "    init_shape = tensor_list[0].size()\n",
    "    if target_sum is None:\n",
    "        target_sum = init_shape[0]\n",
    "    sum_true_vals = 0\n",
    "    for tensor in tensor_list:\n",
    "        assert tensor.size() == init_shape, \"Tensors mismatch in size\"\n",
    "        sum_true_vals += tensor.unique(return_counts=True)[1][1].item()\n",
    "    return sum_true_vals == target_sum\n",
    "    \n",
    "check_sums([vowel_idx, consonant_idx, silence_idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21, 6, 9]\n"
     ]
    }
   ],
   "source": [
    "def split_on_max(atts_list, tensor, feat_idx_dict):\n",
    "    # Get indices corresponding to articulatory features in question\n",
    "    slice_idx = [feat_idx_dict[x] for x in atts_list]\n",
    "    print(slice_idx)\n",
    "    \n",
    "\n",
    "atts_list = [\"front\", \"back\", \"central\"]\n",
    "split_on_max(atts_list, vowels, feat_idx_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'front'"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "height_list.sort()\n",
    "height_idx = [feat_idx_dict[x] for x in height_list]\n",
    "max_idx = test[height_idx].argmax()\n",
    "height_list[max_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "schwa_idx = [feat_idx_dict[x] for x in [\"close-mid\", \"open-mid\", \"rounded\", \"unrounded\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5613911182736047"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(test[schwa_idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0, 'a', 'vowel', 'open', 'front', 'unrounded'],\n",
       " [5, 'e', 'vowel', 'close-mid', 'front', 'unrounded'],\n",
       " [11, 'i', 'vowel', 'close', 'front', 'unrounded'],\n",
       " [43, 'y', 'vowel', 'close', 'front', 'rounded'],\n",
       " [52, 'E', 'vowel', 'open-mid', 'front', 'unrounded'],\n",
       " [58, 'I', 'vowel', 'near-close', 'front', 'unrounded'],\n",
       " [85, 'Y', 'vowel', 'near-close', 'front', 'rounded'],\n",
       " [88, '{', 'vowel', 'near-open', 'front', 'unrounded'],\n",
       " [91, '2', 'vowel', 'close-mid', 'front', 'rounded'],\n",
       " [99, '9', 'vowel', 'open-mid', 'front', 'rounded'],\n",
       " [100, '&', 'vowel', 'open', 'front', 'rounded']]"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "root_dict[\"front\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "front\n"
     ]
    }
   ],
   "source": [
    "def classify_vowel(phone, height_list, height_idx, openness_list, openness_idx, root_dict):\n",
    "    # Get most likely height (front/back/central)\n",
    "    height = height_list[test[height_idx].argmax()]\n",
    "    if height != \"central\":\n",
    "        \n",
    "    \n",
    "\n",
    "classify_vowel(test, height_list, height_idx, openness_list, openness_idx, {})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([False], device='cuda:0'), tensor([800], device='cuda:0'))"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(out[:, schwa_idx].sum(dim=1) > 1).unique(return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'front': {'close',\n",
       "  'close-mid',\n",
       "  'near-close',\n",
       "  'near-open',\n",
       "  'open',\n",
       "  'open-mid'},\n",
       " 'back': {'close', 'close-mid', 'near-close', 'open', 'open-mid'},\n",
       " 'central': {'close', 'close-mid', 'near-close', 'near-open', 'open-mid'}}"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next_step_dict = {}\n",
    "for height, phones in height_dict.items():\n",
    "    subsplit = check_phones_split(openness_list, phones)\n",
    "    subkeys = set()\n",
    "    for key in subsplit:\n",
    "        subkeys.add(key)\n",
    "    next_step_dict[height] = subkeys\n",
    "next_step_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{21: [array([34, 34, 21, 45]), array([52, 12, 21, 45]), array([63, 11, 21, 45]), array([110,  11,  21,  42]), array([15, 35, 21, 45]), array([19, 31, 21, 45]), array([ 0, 31, 21, 42]), array([117,  32,  21,  45]), array([ 4, 12, 21, 42]), array([ 7, 35, 21, 42]), array([ 0, 34, 21, 42])], 6: [array([80, 12,  6, 42]), array([100,  11,   6,  42]), array([11, 34,  6, 45]), array([24, 11,  6, 45]), array([26, 35,  6, 42]), array([ 0, 34,  6, 42]), array([31, 31,  6, 42]), array([ 0, 35,  6, 45]), array([ 6, 12,  6, 45])], 9: [array([ 0, 31,  9, 45]), array([ 0, 31,  9, 42]), array([10, 12, 35,  9]), array([ 0, 11,  9, 42]), array([ 3, 11,  9, 45]), array([ 0, 35,  9, 45]), array([ 0, 35,  9, 42]), array([ 0, 32,  9]), array([ 0, 12,  9, 42])]}\n"
     ]
    }
   ],
   "source": [
    "def setup(feat_idx_dict):\n",
    "    openness_list = [\"open\", \"close-mid\", \"close\", \"open-mid\", \"near-close\", \"near-open\"]\n",
    "    height_list = [\"front\", \"back\", \"central\"]\n",
    "    height_idx = [feat_idx_dict[x] for x in height_list]\n",
    "    openness_idx = [feat_idx_dict[x] for x in openness_list]\n",
    "    return height_list, height_idx, openness_list, openness_idx\n",
    "\n",
    "def check_phones_split(atts_list, phones, att_vec_idx=None):\n",
    "    out_split = {}\n",
    "    for att_idx, att in enumerate(atts_list):\n",
    "        matching_phones = []\n",
    "        for phone in phones:\n",
    "            # Need to do [1:] since first number is phone index itself\n",
    "            if att in phone[1:]:\n",
    "                matching_phones.append(phone)\n",
    "        if len(matching_phones) > 0:\n",
    "            # Can use the index instead of the name \n",
    "            if att_vec_idx is not None:\n",
    "                out_split[att_vec_idx[att_idx]] = matching_phones\n",
    "            else:\n",
    "                out_split[att] = matching_phones\n",
    "    return out_split\n",
    "\n",
    "\n",
    "def build_dict_tree(phones, feat_idx_dict, height_list, openness_list):\n",
    "    root_dict = {} \n",
    "    height_idx = [feat_idx_dict[x] for x in height_list]\n",
    "    openness_idx = [feat_idx_dict[x] for x in openness_list]\n",
    "    root_dict[\"operation\"] = \"max\"\n",
    "    root_dict[\"indices\"] = height_idx\n",
    "    \n",
    "    height_dict = check_phones_split(height_idx, phones, att_vec_idx=height_idx)\n",
    "    print(height_dict)\n",
    "    \n",
    "\n",
    "build_dict_tree(vp, feat_idx_dict, height_list, openness_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "front\n",
      "[[0, 'a', 'vowel', 'open', 'front', 'unrounded'], [100, '&', 'vowel', 'open', 'front', 'rounded']]\n",
      "[[5, 'e', 'vowel', 'close-mid', 'front', 'unrounded'], [91, '2', 'vowel', 'close-mid', 'front', 'rounded']]\n",
      "[[11, 'i', 'vowel', 'close', 'front', 'unrounded'], [43, 'y', 'vowel', 'close', 'front', 'rounded']]\n",
      "[[52, 'E', 'vowel', 'open-mid', 'front', 'unrounded'], [99, '9', 'vowel', 'open-mid', 'front', 'rounded']]\n",
      "[[58, 'I', 'vowel', 'near-close', 'front', 'unrounded'], [85, 'Y', 'vowel', 'near-close', 'front', 'rounded']]\n",
      "[[88, '{', 'vowel', 'near-open', 'front', 'unrounded']]\n",
      "back\n",
      "[[47, 'A', 'vowel', 'open', 'back', 'unrounded'], [73, 'Q', 'vowel', 'open', 'back', 'rounded']]\n",
      "[[21, 'o', 'vowel', 'close-mid', 'back', 'rounded'], [97, '7', 'vowel', 'close-mid', 'back', 'unrounded']]\n",
      "[[37, 'u', 'vowel', 'close', 'back', 'rounded'], [66, 'M', 'vowel', 'close', 'back', 'unrounded']]\n",
      "[[70, 'O', 'vowel', 'open-mid', 'back', 'rounded'], [81, 'V', 'vowel', 'open-mid', 'back', 'unrounded']]\n",
      "[[79, 'U', 'vowel', 'near-close', 'back', 'rounded']]\n",
      "central\n",
      "[[87, '@', 'vowel', 'close-mid', 'open-mid', 'central'], [98, '8', 'vowel', 'close-mid', 'central', 'rounded']]\n",
      "[[89, '}', 'vowel', 'close', 'central', 'rounded'], [90, '1', 'vowel', 'close', 'central', 'unrounded']]\n",
      "[[87, '@', 'vowel', 'close-mid', 'open-mid', 'central'], [92, '3', 'vowel', 'open-mid', 'central', 'unrounded'], [93, '3\\\\', 'vowel', 'open-mid', 'central', 'rounded']]\n",
      "[[59, 'I\\\\', 'vowel', 'near-close', 'central', 'unrounded'], [80, 'U\\\\', 'vowel', 'near-close', 'central', 'rounded']]\n",
      "[[96, '6', 'vowel', 'near-open', 'central']]\n"
     ]
    }
   ],
   "source": [
    "for height, phones in height_dict.items():\n",
    "    print(height)\n",
    "    subsplit = check_phones_split(openness_list, phones)\n",
    "    for sub_phones in subsplit.values():\n",
    "        print(sub_phones)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vowel_phone_tree = {\n",
    "    \"front\": {\n",
    "        \"close\": {\n",
    "            \"rounded\": {\"y\"},\n",
    "            \"unrounded\": {\"i\"}            \n",
    "        },\n",
    "        \"near-close\": {\n",
    "            \"rounded\": {\"Y\"},\n",
    "            \"unrounded\": {\"I\"}            \n",
    "        },\n",
    "        \"near-open\": {\"{\"}, \n",
    "        \"open\": {\n",
    "            \"rounded\": {\"&\"},\n",
    "            \"unrounded\": {\"a\"}\n",
    "        },\n",
    "        \"open-mid\": {\n",
    "            \"rounded\": {\"9\"},\n",
    "            \"unrounded\": {\"E\"}\n",
    "        }\n",
    "    },\n",
    "    \"back\": {\n",
    "        \"close\": {},\n",
    "        \"close-mid\": {},\n",
    "        \"near-close:\": {},\n",
    "        \"open\": {},\n",
    "        \"open-mid\": {}\n",
    "    },\n",
    "    \"central\": {\n",
    "        \"close\": {},\n",
    "        \"close-mid\": {},\n",
    "        \"near-close\": {},\n",
    "        \"near-open\": {},\n",
    "        \"open-mid\": {}\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For splitting the last set of phones\n",
    "def final_split_rounded(phones):\n",
    "    n = len(phones)\n",
    "    # Only one phone, don't need to split\n",
    "    if n == 1:\n",
    "        return phones\n",
    "    elif n == 2:\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "front\n",
      "[[0, 'a', 'vowel', 'open', 'front', 'unrounded'], [100, '&', 'vowel', 'open', 'front', 'rounded']]\n",
      "[[5, 'e', 'vowel', 'close-mid', 'front', 'unrounded'], [91, '2', 'vowel', 'close-mid', 'front', 'rounded']]\n",
      "[[11, 'i', 'vowel', 'close', 'front', 'unrounded'], [43, 'y', 'vowel', 'close', 'front', 'rounded']]\n",
      "[[52, 'E', 'vowel', 'open-mid', 'front', 'unrounded'], [99, '9', 'vowel', 'open-mid', 'front', 'rounded']]\n",
      "[[58, 'I', 'vowel', 'near-close', 'front', 'unrounded'], [85, 'Y', 'vowel', 'near-close', 'front', 'rounded']]\n",
      "[[88, '{', 'vowel', 'near-open', 'front', 'unrounded']]\n",
      "back\n",
      "[[47, 'A', 'vowel', 'open', 'back', 'unrounded'], [73, 'Q', 'vowel', 'open', 'back', 'rounded']]\n",
      "[[21, 'o', 'vowel', 'close-mid', 'back', 'rounded'], [97, '7', 'vowel', 'close-mid', 'back', 'unrounded']]\n",
      "[[37, 'u', 'vowel', 'close', 'back', 'rounded'], [66, 'M', 'vowel', 'close', 'back', 'unrounded']]\n",
      "[[70, 'O', 'vowel', 'open-mid', 'back', 'rounded'], [81, 'V', 'vowel', 'open-mid', 'back', 'unrounded']]\n",
      "[[79, 'U', 'vowel', 'near-close', 'back', 'rounded']]\n",
      "central\n",
      "[[87, '@', 'vowel', 'close-mid', 'open-mid', 'central'], [98, '8', 'vowel', 'close-mid', 'central', 'rounded']]\n",
      "[[89, '}', 'vowel', 'close', 'central', 'rounded'], [90, '1', 'vowel', 'close', 'central', 'unrounded']]\n",
      "[[87, '@', 'vowel', 'close-mid', 'open-mid', 'central'], [92, '3', 'vowel', 'open-mid', 'central', 'unrounded'], [93, '3\\\\', 'vowel', 'open-mid', 'central', 'rounded']]\n",
      "[[59, 'I\\\\', 'vowel', 'near-close', 'central', 'unrounded'], [80, 'U\\\\', 'vowel', 'near-close', 'central', 'rounded']]\n",
      "[[96, '6', 'vowel', 'near-open', 'central']]\n"
     ]
    }
   ],
   "source": [
    "for height, phones in height_dict.items():\n",
    "    print(height)\n",
    "    subsplit = check_phones_split(openness_list, phones)\n",
    "    for sub_phones in subsplit.values():\n",
    "        print(sub_phones)\n",
    "        #if len(sub_phones) > 2:\n",
    "        #    print(sub_phones)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_set(input_set):\n",
    "    line = \"\"\n",
    "    for attribute in input_set:\n",
    "        line += attribute + \" \"\n",
    "    print(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "velar voiced alveolar glottal lateral coronal dorsal labial-palatal trill stop palatal apical dental plosive approximant bilabial postalveolar pharyngeal fricative affricate voiceless labial alveolo-palatal flap epiglottal labial-velar nasal click palatal-velar uvular retroflex labiodental \n"
     ]
    }
   ],
   "source": [
    "line = \"\"\n",
    "for attribute in ca:\n",
    "    line += attribute + \" \"\n",
    "print(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'place_general' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-60-f123ef80b7a5>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mfull_dict\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[1;32mfor\u001b[0m \u001b[0matt\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mplace_general\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m     \u001b[0matt_phones\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mphone\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mcp\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0matt\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mphone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'place_general' is not defined"
     ]
    }
   ],
   "source": [
    "full_dict = {}\n",
    "for att in place_general:\n",
    "    att_phones = []\n",
    "    for phone in cp:\n",
    "        if att in phone:\n",
    "            att_phones.append(phone)\n",
    "    full_dict[att] = att_phones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "voiced labial-velar affricate apical click voiceless plosive \n"
     ]
    }
   ],
   "source": [
    "place_top = {\"coronal\", \"labial\", \"dorsal\", \"pharyngeal\", \"glottal\", \"epiglottal\", \"alveolo-palatal\", \"labiodental\"}\n",
    "place_coronal = {\"dental\", \"alveolar\", \"postalveolar\", \"retroflex\", \"palatal\"}\n",
    "place_dorsal = {\"palatal\", \"velar\", \"uvular\", \"palatal-velar\"}\n",
    "place_labial = {\"bilabial\", \"labiodental\", \"labial-palatal\"}\n",
    "manner = {\"nasal\", \"stop\", \"fricative\", \"approximant\", \"flap\", \"trill\", \"lateral\"}\n",
    "\n",
    "remaining_atts = set()\n",
    "for att in ca:\n",
    "    selected_atts = place_top.union(manner)\n",
    "    selected_atts = selected_atts.union(place_coronal)\n",
    "    selected_atts = selected_atts.union(place_dorsal)\n",
    "    selected_atts = selected_atts.union(place_labial)\n",
    "    if att not in selected_atts:\n",
    "        remaining_atts.add(att)\n",
    "\n",
    "print_set(remaining_atts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class BinaryTree(object):\n",
    "    def __init__(self, key):\n",
    "        self.left = None\n",
    "        self.right = None\n",
    "        self.key = key\n",
    "        self.split_idx = None\n",
    "        self.left_is_leaf = False\n",
    "        self.right_is_leaf = False\n",
    "        \n",
    "    def display(self):\n",
    "        lines, _, _, _ = self._display_aux()\n",
    "        for line in lines:\n",
    "            print(line)\n",
    "            \n",
    "    def save(self, filepath):\n",
    "        lines, _, _, _ = self._display_aux()\n",
    "        with open(filepath, \"w\") as f:\n",
    "            for line in lines:\n",
    "                f.write(line + \"\\n\")\n",
    "\n",
    "    def _display_aux(self):\n",
    "        \"\"\"Returns list of strings, width, height, and horizontal coordinate of the root.\"\"\"\n",
    "        # No child.\n",
    "        if self.right is None and self.left is None:\n",
    "            line = '%s' % self.key\n",
    "            width = len(line)\n",
    "            height = 1\n",
    "            middle = width // 2\n",
    "            return [line], width, height, middle\n",
    "\n",
    "        # Only left child.\n",
    "        if self.right is None:\n",
    "            lines, n, p, x = self.left._display_aux()\n",
    "            s = '%s' % self.key\n",
    "            u = len(s)\n",
    "            first_line = (x + 1) * ' ' + (n - x - 1) * '_' + s\n",
    "            second_line = x * ' ' + '/' + (n - x - 1 + u) * ' '\n",
    "            shifted_lines = [line + u * ' ' for line in lines]\n",
    "            return [first_line, second_line] + shifted_lines, n + u, p + 2, n + u // 2\n",
    "\n",
    "        # Only right child.\n",
    "        if self.left is None:\n",
    "            lines, n, p, x = self.right._display_aux()\n",
    "            s = '%s' % self.key\n",
    "            u = len(s)\n",
    "            first_line = s + x * '_' + (n - x) * ' '\n",
    "            second_line = (u + x) * ' ' + '\\\\' + (n - x - 1) * ' '\n",
    "            shifted_lines = [u * ' ' + line for line in lines]\n",
    "            return [first_line, second_line] + shifted_lines, n + u, p + 2, u // 2\n",
    "\n",
    "        # Two children.\n",
    "        left, n, p, x = self.left._display_aux()\n",
    "        right, m, q, y = self.right._display_aux()\n",
    "        s = '%s' % self.key\n",
    "        u = len(s)\n",
    "        first_line = (x + 1) * ' ' + (n - x - 1) * '_' + s + y * '_' + (m - y) * ' '\n",
    "        second_line = x * ' ' + '/' + (n - x - 1 + u + y) * ' ' + '\\\\' + (m - y - 1) * ' '\n",
    "        if p < q:\n",
    "            left += [n * ' '] * (q - p)\n",
    "        elif q < p:\n",
    "            right += [m * ' '] * (p - q)\n",
    "        zipped_lines = zip(left, right)\n",
    "        lines = [first_line, second_line] + [a + u * ' ' + b for a, b in zipped_lines]\n",
    "        return lines, n + m + u, max(p, q) + 2, n + u // 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'BinaryTree' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-104-69f0f1cd6f22>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    101\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mcurr_tree\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    102\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 103\u001b[1;33m \u001b[0mcurr_tree\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbuild_tree\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mca\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeat_idx_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0muse_indices\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mis_first\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    104\u001b[0m \u001b[0mcurr_tree\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"consonant_tree\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    105\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-104-69f0f1cd6f22>\u001b[0m in \u001b[0;36mbuild_tree\u001b[1;34m(phones, allowable_atts, feat_idx_dict, use_indices, is_first)\u001b[0m\n\u001b[0;32m     74\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     75\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0muse_indices\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 76\u001b[1;33m         \u001b[0mcurr_tree\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mBinaryTree\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbest_feat\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     77\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     78\u001b[0m         \u001b[0mcurr_tree\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mBinaryTree\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfeat_idx_dict\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mbest_feat\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'BinaryTree' is not defined"
     ]
    }
   ],
   "source": [
    "# Check score\n",
    "def score_split(feature, phones):\n",
    "    n_tr = 0\n",
    "    n_fa = 0\n",
    "    for phone in phones:\n",
    "        if feature in phone[2:]:\n",
    "            n_tr += 1\n",
    "        else:\n",
    "            n_fa += 1\n",
    "    total = n_tr + n_fa\n",
    "    percent = n_tr / total\n",
    "    return abs(percent - 0.5)\n",
    "\n",
    "def best_split(phones, allowable_atts):\n",
    "    atts_list = []\n",
    "    atts_scores = []\n",
    "#     print(\"phones: {}\".format(str(phones)))\n",
    "#     print(\"all atts: {}\".format(str(all_attributes)))\n",
    "#     print(\"selected atts: {}\".format(str(selected_atts)))\n",
    "    for attribute in allowable_atts:\n",
    "        score = score_split(attribute, phones)\n",
    "        atts_list.append(attribute)\n",
    "        atts_scores.append(score)\n",
    "    best_idx = np.argmin(atts_scores)\n",
    "    return atts_list[best_idx]\n",
    "\n",
    "def do_split(feature, phones, allowable_atts):\n",
    "    true_phones = []\n",
    "    false_phones = []\n",
    "    true_attributes = set()\n",
    "    false_attributes = set()\n",
    "    for phone in phones:\n",
    "        if feature in phone:\n",
    "            true_phones.append(phone)\n",
    "            for attribute in phone[2:]:\n",
    "                if attribute in allowable_atts:\n",
    "                    true_attributes.add(attribute)\n",
    "        else:\n",
    "            false_phones.append(phone)\n",
    "            for attribute in phone[2:]:\n",
    "                if attribute in allowable_atts:\n",
    "                    false_attributes.add(attribute)\n",
    "    return true_phones, false_phones, true_attributes, false_attributes    \n",
    "    \n",
    "\n",
    "\n",
    "# True values (> 0.5 are on the left, false values on the right)\n",
    "def build_tree(phones, allowable_atts, feat_idx_dict, use_indices=True, is_first=False):\n",
    "\n",
    "    # Find best feature to split on. Update binary tree\n",
    "    best_feat = best_split(phones, allowable_atts)\n",
    "    \n",
    "    if not use_indices:\n",
    "        curr_tree = BinaryTree(best_feat)\n",
    "    else:\n",
    "        curr_tree = BinaryTree(feat_idx_dict[best_feat])\n",
    "    allowable_atts.remove(best_feat)\n",
    "    tr_phones, fa_phones, tr_atts, fa_atts = do_split(best_feat, phones, allowable_atts)\n",
    "    # Update leaves of tree if possible\n",
    "    if len(tr_phones) == 1:\n",
    "        # Convert e.g. ['b consonant voiced bilabial stop labial'] to \"b\"\n",
    "        if not use_indices:\n",
    "            tr_phone = tr_phones[0][1]\n",
    "        else:\n",
    "            tr_phone = tr_phones[0][0]\n",
    "        curr_tree.left = BinaryTree(tr_phone)\n",
    "    else:\n",
    "        curr_tree.left = build_tree(tr_phones, tr_atts, feat_idx_dict, use_indices)\n",
    "        \n",
    "        \n",
    "    if len(fa_phones) == 1:\n",
    "        if not use_indices:\n",
    "            fa_phone = fa_phones[0][1]\n",
    "        else:\n",
    "            fa_phone = fa_phones[0][0]\n",
    "        curr_tree.right = BinaryTree(fa_phone)\n",
    "    else:\n",
    "        curr_tree.right = build_tree(fa_phones, fa_atts, feat_idx_dict, use_indices)\n",
    "    return curr_tree\n",
    "    \n",
    "curr_tree = build_tree(cp, ca, feat_idx_dict, use_indices=False, is_first=True)\n",
    "curr_tree.save(\"consonant_tree\")\n",
    "\n",
    "vowel_tree = build_tree(vp, va, feat_idx_dict, use_indices=False, is_first=True)\n",
    "vowel_tree.save(\"vowel_tree\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_replicated = torch.repeat_interleave(out, repeats=num_phones, dim=0)\n",
    "mapping_t = torch.from_numpy(mapping).float().to(device)\n",
    "mapping_t = mapping_t.repeat(800, 1)\n",
    "dists = F.pairwise_distance(out_replicated, mapping_t)\n",
    "cosines = F.cosine_similarity(out_replicated, mapping_t)\n",
    "cosines = cosines.view(n, num_phones)\n",
    "dists = dists.view(n, num_phones)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
